# Cognitive benchmarking in large models

## Overview

In this session, participants will explore the fundamentals of Large Language Models (LLMs), Vision-Language Models (VLMs), and reasoning models.
The LLM and VLM sections will each include:
1)	A concise theoretical overview
2)	Key practical considerations
3)	Hands-on exercises

## Instructors

::::{grid}
:::{grid-item}
![Lucas Gomez](images/profile_lucas_gomez.jpg)
[Lucas Gomez](https://www.lucasgomez.ca/about)
:::

:::{grid-item}
![](Zihan Weng)
[Zihan Weng](https://github.com/bat0001)
:::

:::{grid-item}
![Declan Campbell](images/profile_declan_campbell.png)
[Declan Campbell](https://scholar.google.com/citations?user=QS1P0NYAAAAJ&hl=en)
:::
::::

**Lucas Gomez** is a PhD student in the Integrated Program in Neuroscience at McGill University. His research in the BashivanLab focuses on building large scale deep learning models of visual working memory that predict prefrontal cortex activity. He has a Bachelors of Computer Science from Carleton University in Ottawa, and he is broadly interested in the intersection between AI and the brain sciences.

**Zihan Weng** is a PhD Student in Neuroscience at McGill University, CA.  

**Declan Campbell** is a PhD Student at Princeton University, USA.

## Objectives

This session is divided into three parts:

---

### **Large Language Models (LLMs)**

- **Learning the basics of LLMs**:
    - Architecture
    - Tokenization
    - Training and finetuning strategies
    - In-context learning

- **Practical considerations**:
    - APIs and inference interfaces
    - Controlling LLM outputs
    - Prompt structure
    - Differences between LLM variants
    - Parsing and evaluating responses

- **Hands-on** - Behavioral evaluation of an LLM:
    - Huggingface
    - OpenRouter
    - Google colab

---

### **Vision-Language Models (VLMs)**

- **Learning the basics of VLMs**:
    - Image encoders
    - Image projection layers connecting encoders to LLM backbones
    - Image tokenization
    - Training regimes

- **Practical considerations**:
    - Computational differences ot LLMs
    - Image prompting formats

- **Hands-on** - Cognitive evaluation of a VLM:
    - Huggingface
    - OpenRouter
    - Google colab

---

### **Reasoning Models**

- **Learning the basics of reasoning-enhanced models**:
    - Chain-of-thought (CoT) prompting
    - R1-style reasoning training and supervised reasoning traces

- **Practical considerations**:
    - Ensuring ad-hoc reasoning
    - Understanding reasoning visibility differences
    - Controlling reasoning effort and computation

---

## Materials

Colab notebook for hands on sections - *links to be added*
