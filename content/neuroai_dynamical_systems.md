# Computation in Neuroscience & AI: a Dynamical Systems Perspective with RNNs

## Overview

The brain is a deeply complex dynamical system continuously interacting with its environment. How can experimental and computational neuroscientists make sense of this complexity _in a principled way_?

This workshop introduces a dynamical systems perspective on neural computation using recurrent neural networks (RNNs) as a central modeling tool. We will show how abstract RNN models can capture meaningful neural interactions, sharpen intuitions, and provide non-trivial insights into the computational mechanisms underlying behavior.

## Instructors

::::{grid}
:::{grid-item}
```{image} https://avatars.githubusercontent.com/u/102626067?v=4
:alt: profile
:class: bg-primary mb-1
:height: 200px
:align: center
```
[ Doris Voina, PhD](https://dorisvoina.org/)
:::

:::{grid-item}
```{image} https://avatars.githubusercontent.com/u/44071291?v=4
:alt: profile
:class: bg-primary mb-1
:height: 200px
:align: center
```
[Ladan Shahshahani](https://scholar.google.com/citations?user=Mn5J97oAAAAJ&hl=en)
:::

::::

**Doris Voina, PhD**  is a Postdoctoral Scholar in the [SNAIL](https://www.snailab.ca/) laboratory at Université de Montréal with Dr. Shahab Bakhtiari. She earned her PhD in Applied Mathematics from the University of Washington (2022), with a broad interest in computational neuroscience. Her work focuses on developing computational and AI methods for data analysis to better understand neural mechanisms underlying learning and perception.

**Ladan Shahshahani, PhD** is a Postdoctoral Scholar in the [SNAIL](https://www.snailab.ca/) laboratory at Université de Montréal where she works with Dr. Shahab Bakhtiari to investigate how the brain carries out mental simulation using psychophysics and MEG/fMRI. She is particularly interested in how the dynamics of these neural transformations can guide the development of modern AI systems, inspiring models that capture the brain’s flexible, simulation-driven computations. Her background includes research on visual working memory, cerebellar and subcortical contributions to cognition, and computational approaches to neuroimaging, which now shape her broader goal of understanding and modeling how the brain builds and manipulates internal representations.

## Objectives

This session is divided into two parts:

### Part 1 — Introduction: A Dynamical Systems Framework Using RNNs
_How to do computational neuroscience by training artificial neural networks_

Participants will:
 * Learn the basics of recurrent neural networks
 * Understand the dynamical systems perspective applied to RNNs
 * Work through simple hands-on exercises to build intuition for what RNNs are and what kinds of computations they can perform

### Part 2 — A Case Study: Modeling a Context-Integration Task with RNNs

In this more involved section, participants will:

 * Train an RNN to perform a context-integration behavioral task
 * Perform dimensionality reduction beyond standard PCA
 * Characterize the RNN’s dynamics via neural manifolds (e.g., line attractors)
 * Compare RNN trajectories with neural population data from Mante & Sussillo (2013)
 * Extract computational insights about how the brain may solve the task based on the RNN’s inferred dynamics

### Bonus / Homework
Additional optional exercises for participants who want to explore further

## Material

::::{grid}
:::{grid-item}
```{image} images/logo_colab.png
:alt: logo colab
:class: bg-primary mb-1
:height: 200px
:align: center
```
[Colab notebooks for dynamical systems with RNNs](https://colab.research.google.com/drive/1Xxb-pNG8imI1HxC5VVhiFH-Xp4Y1z-KA#scrollTo=a5hMFudS1OMT)
:::
::::
